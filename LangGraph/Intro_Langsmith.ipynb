{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "990cb5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Jeevan\\Agentic_AI\\LangGraph_Langchain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "import requests\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c47e4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476e1ef7",
   "metadata": {},
   "source": [
    "FIRST SETUP LANGSMITH at https://langsmith.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5441b4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f551b156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Serper API key found\n",
      "🔍 Testing Google search...\n",
      "✗ Error with Serper API: 403 Client Error: Forbidden for url: https://google.serper.dev/search?q=what+is+the+capital+of+france&gl=us&hl=en&num=10\n",
      "This might be due to:\n",
      "  1. Invalid API key\n",
      "  2. API quota exceeded\n",
      "  3. Network connectivity issues\n"
     ]
    }
   ],
   "source": [
    "# Google Serper API Setup and Testing\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "# Check if Serper API key is available\n",
    "serper_api_key = os.getenv(\"SERPER_API_KEY\")\n",
    "if serper_api_key:\n",
    "    print(\"✓ Serper API key found\")\n",
    "    try:\n",
    "        # Create Serper wrapper with API key\n",
    "        serper = GoogleSerperAPIWrapper(serper_api_key=serper_api_key)\n",
    "        \n",
    "        # Test the search functionality\n",
    "        print(\"🔍 Testing Google search...\")\n",
    "        result = serper.run(\"what is the capital of france\")\n",
    "        print(f\"Search result: {result}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error with Serper API: {e}\")\n",
    "        print(\"This might be due to:\")\n",
    "        print(\"  1. Invalid API key\")\n",
    "        print(\"  2. API quota exceeded\")\n",
    "        print(\"  3. Network connectivity issues\")\n",
    "else:\n",
    "    print(\"⚠️ No Serper API key found\")\n",
    "    print(\"To use Google search functionality:\")\n",
    "    print(\"  1. Sign up at https://serper.dev/\")\n",
    "    print(\"  2. Get your API key\")\n",
    "    print(\"  3. Add SERPER_API_KEY to your .env file\")\n",
    "    print(\"  4. Restart your notebook\")\n",
    "    \n",
    "    # Create a mock serper for demonstration\n",
    "    class MockSerper:\n",
    "        def run(self, query):\n",
    "            return f\"Mock search result for: {query}\"\n",
    "    \n",
    "    serper = MockSerper()\n",
    "    print(\"Using mock search for demonstration...\")\n",
    "    result = serper.run(\"what is the capital of france\")\n",
    "    print(f\"Mock result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff87f1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LangGraph workflow created successfully!\n",
      "Graph structure:\n",
      "  START -> agent -> (continue/end)\n",
      "  continue -> agent\n",
      "  end -> END\n"
     ]
    }
   ],
   "source": [
    "# LangGraph Example - Simple Chat Agent with Search\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Define the state for our graph\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Create the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "def call_model(state: AgentState):\n",
    "    \"\"\"Call the LLM with the current messages.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Determine if we should continue the conversation.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Simple logic: continue if it's a human message\n",
    "    if isinstance(last_message, HumanMessage):\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"agent\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"✓ LangGraph workflow created successfully!\")\n",
    "print(\"Graph structure:\")\n",
    "print(\"  START -> agent -> (continue/end)\")\n",
    "print(\"  continue -> agent\")\n",
    "print(\"  end -> END\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b1746b",
   "metadata": {},
   "source": [
    "Langchain wrapper class for converting functions into Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "869f6208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "tool_search = Tool(\n",
    "    name=\"search\",\n",
    "    func=serper.run,\n",
    "    description=\"Useful for when you need more information from an online search\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362905b7",
   "metadata": {},
   "source": [
    "Now we can try out the tool in Langchain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "675f6dbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://google.serper.dev/search?q=what+is+the+capital+of+India%3F&gl=us&hl=en&num=10",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtool_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat is the capital of India?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI\\LangGraph_Langchain\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:604\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    596\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    598\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    601\u001b[39m     **kwargs: Any,\n\u001b[32m    602\u001b[39m ) -> Any:\n\u001b[32m    603\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI\\LangGraph_Langchain\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:888\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    887\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    889\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    890\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI\\LangGraph_Langchain\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:857\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    855\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m._run):\n\u001b[32m    856\u001b[39m         tool_kwargs |= {config_param: config}\n\u001b[32m--> \u001b[39m\u001b[32m857\u001b[39m     response = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) != \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI\\LangGraph_Langchain\\.venv\\Lib\\site-packages\\langchain_core\\tools\\simple.py:105\u001b[39m, in \u001b[36mTool._run\u001b[39m\u001b[34m(self, config, run_manager, *args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m.func):\n\u001b[32m    104\u001b[39m         kwargs[config_param] = config\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mTool does not support sync invocation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI\\LangGraph_Langchain\\.venv\\Lib\\site-packages\\langchain_community\\utilities\\google_serper.py:74\u001b[39m, in \u001b[36mGoogleSerperAPIWrapper.run\u001b[39m\u001b[34m(self, query, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     73\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run query through GoogleSearch and parse result.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_google_serper_api_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtbs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtbs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43msearch_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_results(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI\\LangGraph_Langchain\\.venv\\Lib\\site-packages\\langchain_community\\utilities\\google_serper.py:164\u001b[39m, in \u001b[36mGoogleSerperAPIWrapper._google_serper_api_results\u001b[39m\u001b[34m(self, search_term, search_type, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m params = {\n\u001b[32m    158\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mq\u001b[39m\u001b[33m\"\u001b[39m: search_term,\n\u001b[32m    159\u001b[39m     **{key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m},\n\u001b[32m    160\u001b[39m }\n\u001b[32m    161\u001b[39m response = requests.post(\n\u001b[32m    162\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://google.serper.dev/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, headers=headers, params=params\n\u001b[32m    163\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m search_results = response.json()\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m search_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI\\LangGraph_Langchain\\.venv\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://google.serper.dev/search?q=what+is+the+capital+of+India%3F&gl=us&hl=en&num=10"
     ]
    }
   ],
   "source": [
    "tool_search.invoke(\"what is the capital of India?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a5b215",
   "metadata": {},
   "source": [
    "Now we will write a tool ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e788dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "795ddec7",
   "metadata": {},
   "source": [
    "# LangGraph Introduction with LangSmith\n",
    "\n",
    "This notebook demonstrates the basics of LangGraph and LangSmith integration.\n",
    "\n",
    "## What is LangGraph?\n",
    "LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends LangChain's core concepts to make it easier to build complex, multi-step workflows.\n",
    "\n",
    "## Key Features Demonstrated:\n",
    "- ✅ **State Management**: Using TypedDict for structured state\n",
    "- ✅ **Graph Construction**: Building workflows with nodes and edges\n",
    "- ✅ **Conditional Logic**: Dynamic flow control based on state\n",
    "- ✅ **LangSmith Integration**: Tracing and monitoring (when configured)\n",
    "\n",
    "## Setup Requirements:\n",
    "\n",
    "### Required:\n",
    "- **OpenAI API Key**: For LLM functionality\n",
    "- **LangSmith Account**: For tracing and monitoring (optional but recommended)\n",
    "\n",
    "### Optional:\n",
    "- **Serper API Key**: For Google search functionality\n",
    "- **Gradio**: For building web interfaces\n",
    "\n",
    "## Next Steps:\n",
    "1. Set up your API keys in the `.env` file\n",
    "2. Explore more complex graph patterns\n",
    "3. Add tools and external integrations\n",
    "4. Build interactive applications with Gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89ea7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e987ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
