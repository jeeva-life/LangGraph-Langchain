{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224f01c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SQLite checkpoint memory initialized successfully!\n",
      "Database path: d:\\Jeevan\\Agentic_AI\\LangGraph_Langchain\\LangGraph\\memory.db\n",
      "Connection status: Connected\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Set up database path\n",
    "db_path = \"memory.db\"\n",
    "\n",
    "# Create database connection\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "\n",
    "# Create SQLite checkpoint saver\n",
    "sql_memory = SqliteSaver(conn)\n",
    "\n",
    "print(\"‚úÖ SQLite checkpoint memory initialized successfully!\")\n",
    "print(f\"Database path: {os.path.abspath(db_path)}\")\n",
    "print(f\"Connection status: {'Connected' if conn else 'Failed'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e691530f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI LLM initialized\n",
      "‚úÖ LangGraph workflow with SQLite memory created!\n",
      "Features:\n",
      "  - Persistent conversation memory\n",
      "  - State checkpointing\n",
      "  - Thread-based conversations\n"
     ]
    }
   ],
   "source": [
    "# Example: LangGraph with SQLite Memory Persistence\n",
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Ensure SQLite memory is initialized (in case cells are run out of order)\n",
    "if 'sql_memory' not in globals():\n",
    "    print(\"üîÑ Reinitializing SQLite memory...\")\n",
    "    db_path = \"memory.db\"\n",
    "    conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "    sql_memory = SqliteSaver(conn)\n",
    "    print(\"‚úÖ SQLite checkpoint memory reinitialized!\")\n",
    "\n",
    "# Check for OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    print(\"‚ö†Ô∏è No OpenAI API key found. Please set OPENAI_API_KEY in your .env file\")\n",
    "    print(\"This example will use a mock LLM for demonstration\")\n",
    "    \n",
    "    class MockLLM:\n",
    "        def invoke(self, messages):\n",
    "            return AIMessage(content=f\"Mock response to: {messages[-1].content}\")\n",
    "    \n",
    "    llm = MockLLM()\n",
    "else:\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "    print(\"‚úÖ OpenAI LLM initialized\")\n",
    "\n",
    "# Define the state for our graph\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def call_model(state: AgentState):\n",
    "    \"\"\"Call the LLM with the current messages.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Determine if we should continue the conversation.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Simple logic: continue if it's a human message\n",
    "    if isinstance(last_message, HumanMessage):\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"agent\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compile the graph with SQLite memory\n",
    "app = workflow.compile(checkpointer=sql_memory)\n",
    "\n",
    "print(\"‚úÖ LangGraph workflow with SQLite memory created!\")\n",
    "print(\"Features:\")\n",
    "print(\"  - Persistent conversation memory\")\n",
    "print(\"  - State checkpointing\")\n",
    "print(\"  - Thread-based conversations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2a0e3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing SQLite Memory Persistence...\n",
      "==================================================\n",
      "‚úÖ LangGraph app found, proceeding with tests...\n",
      "\n",
      "üìù Test 1: New conversation thread\n",
      "Response: Hello Alice! It's nice to meet you. How can I assist you today?\n",
      "Response: Your name is Alice.\n",
      "\n",
      "üìù Test 2: Another conversation thread\n",
      "Response: Nice to meet you, Bob! How can I assist you today?\n",
      "\n",
      "üìù Test 3: Back to first thread (should remember Alice)\n",
      "Response: Your name is Alice.\n",
      "\n",
      "‚úÖ Memory persistence test completed!\n",
      "Each thread maintains its own conversation history.\n"
     ]
    }
   ],
   "source": [
    "# Test the persistent memory functionality\n",
    "print(\"üß™ Testing SQLite Memory Persistence...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Ensure all required variables are available\n",
    "if 'app' not in globals():\n",
    "    print(\"‚ùå LangGraph app not found. Please run the previous cell first.\")\n",
    "    print(\"This cell requires the LangGraph workflow to be compiled.\")\n",
    "    print(\"Please run the 'Example: LangGraph with SQLite Memory Persistence' cell first.\")\n",
    "else:\n",
    "    print(\"‚úÖ LangGraph app found, proceeding with tests...\")\n",
    "    \n",
    "    # Test 1: Create a new conversation thread\n",
    "    print(\"\\nüìù Test 1: New conversation thread\")\n",
    "    thread_id = \"test_conversation_1\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "    # Start a conversation\n",
    "    result1 = app.invoke(\n",
    "        {\"messages\": [HumanMessage(content=\"Hello! My name is Alice.\")]},\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"Response: {result1['messages'][-1].content}\")\n",
    "\n",
    "    # Continue the conversation\n",
    "    result2 = app.invoke(\n",
    "        {\"messages\": [HumanMessage(content=\"What's my name?\")]},\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"Response: {result2['messages'][-1].content}\")\n",
    "\n",
    "    # Test 2: Create another conversation thread\n",
    "    print(\"\\nüìù Test 2: Another conversation thread\")\n",
    "    thread_id_2 = \"test_conversation_2\"\n",
    "    config2 = {\"configurable\": {\"thread_id\": thread_id_2}}\n",
    "\n",
    "    result3 = app.invoke(\n",
    "        {\"messages\": [HumanMessage(content=\"Hello! My name is Bob.\")]},\n",
    "        config=config2\n",
    "    )\n",
    "    print(f\"Response: {result3['messages'][-1].content}\")\n",
    "\n",
    "    # Test 3: Go back to first thread (should remember Alice)\n",
    "    print(\"\\nüìù Test 3: Back to first thread (should remember Alice)\")\n",
    "    result4 = app.invoke(\n",
    "        {\"messages\": [HumanMessage(content=\"What's my name again?\")]},\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"Response: {result4['messages'][-1].content}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Memory persistence test completed!\")\n",
    "    print(\"Each thread maintains its own conversation history.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d8190e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Advanced SQLite Memory Features...\n",
      "==================================================\n",
      "‚úÖ All required variables found, proceeding with advanced features...\n",
      "\n",
      "üìã Available conversation threads:\n",
      "  1. test_conversation_1\n",
      "  2. test_conversation_2\n",
      "\n",
      "üìú Conversation history for thread: test_conversation_1\n",
      "  Total messages: 12\n",
      "    1. [Human]: Hello! My name is Alice.\n",
      "    2. [AI]: Hello Alice! It's nice to meet you. How are you today?\n",
      "    3. [Human]: What's my name?\n",
      "    4. [AI]: Your name is Alice.\n",
      "    5. [Human]: What's my name again?\n",
      "    6. [AI]: Your name is Alice.\n",
      "    7. [Human]: Hello! My name is Alice.\n",
      "    8. [AI]: Hello Alice! It's nice to meet you. How can I assist you today?\n",
      "    9. [Human]: What's my name?\n",
      "    10. [AI]: Your name is Alice.\n",
      "    11. [Human]: What's my name again?\n",
      "    12. [AI]: Your name is Alice.\n",
      "\n",
      "üìä Database Statistics:\n",
      "  Total checkpoints: 24\n",
      "  Total threads: 2\n",
      "  Database size: 4096 bytes (4.00 KB)\n",
      "\n",
      "‚úÖ Advanced memory features demonstrated!\n"
     ]
    }
   ],
   "source": [
    "# Advanced Memory Features\n",
    "print(\"üîß Advanced SQLite Memory Features...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Ensure all required variables are available\n",
    "if 'app' not in globals() or 'conn' not in globals():\n",
    "    print(\"‚ùå Required variables not found. Please run the previous cells first.\")\n",
    "    print(\"This cell requires the LangGraph app and database connection.\")\n",
    "    print(\"Please run the first two cells in order.\")\n",
    "else:\n",
    "    print(\"‚úÖ All required variables found, proceeding with advanced features...\")\n",
    "    \n",
    "    # List all conversation threads\n",
    "    print(\"\\nüìã Available conversation threads:\")\n",
    "    try:\n",
    "        # Get all thread IDs from the database\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT DISTINCT thread_id FROM checkpoints\")\n",
    "        threads = cursor.fetchall()\n",
    "        \n",
    "        if threads:\n",
    "            for i, (thread_id,) in enumerate(threads, 1):\n",
    "                print(f\"  {i}. {thread_id}\")\n",
    "        else:\n",
    "            print(\"  No conversation threads found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error retrieving threads: {e}\")\n",
    "\n",
    "    # Get conversation history for a specific thread\n",
    "    if 'config' in globals():\n",
    "        print(f\"\\nüìú Conversation history for thread: {config['configurable']['thread_id']}\")\n",
    "        try:\n",
    "            # Get the latest state for the thread\n",
    "            state = app.get_state(config)\n",
    "            if state and state.values:\n",
    "                messages = state.values.get(\"messages\", [])\n",
    "                print(f\"  Total messages: {len(messages)}\")\n",
    "                for i, msg in enumerate(messages, 1):\n",
    "                    msg_type = \"Human\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "                    content = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
    "                    print(f\"    {i}. [{msg_type}]: {content}\")\n",
    "            else:\n",
    "                print(\"  No conversation history found\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error retrieving history: {e}\")\n",
    "    else:\n",
    "        print(\"\\nüìú No conversation thread selected for history display\")\n",
    "\n",
    "    # Database statistics\n",
    "    print(f\"\\nüìä Database Statistics:\")\n",
    "    try:\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM checkpoints\")\n",
    "        checkpoint_count = cursor.fetchone()[0]\n",
    "        print(f\"  Total checkpoints: {checkpoint_count}\")\n",
    "        \n",
    "        cursor.execute(\"SELECT COUNT(DISTINCT thread_id) FROM checkpoints\")\n",
    "        thread_count = cursor.fetchone()[0]\n",
    "        print(f\"  Total threads: {thread_count}\")\n",
    "        \n",
    "        # Get database file size\n",
    "        db_size = os.path.getsize(db_path)\n",
    "        print(f\"  Database size: {db_size} bytes ({db_size/1024:.2f} KB)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error getting statistics: {e}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Advanced memory features demonstrated!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af02fb",
   "metadata": {},
   "source": [
    "# LangGraph SQLite Memory Persistence\n",
    "\n",
    "This notebook demonstrates how to use SQLite as a persistent memory store for LangGraph applications.\n",
    "\n",
    "## What is SQLite Memory in LangGraph?\n",
    "\n",
    "SQLite memory allows LangGraph applications to:\n",
    "- **Persist conversation state** across sessions\n",
    "- **Maintain multiple conversation threads** independently\n",
    "- **Store checkpoints** for complex workflows\n",
    "- **Resume conversations** after application restarts\n",
    "\n",
    "## Key Features Demonstrated:\n",
    "\n",
    "### ‚úÖ **Persistent State Management**\n",
    "- Conversation history is saved to SQLite database\n",
    "- State persists across application restarts\n",
    "- Multiple conversation threads supported\n",
    "\n",
    "### ‚úÖ **Thread-Based Conversations**\n",
    "- Each conversation has a unique thread ID\n",
    "- Threads maintain independent conversation histories\n",
    "- Easy to switch between different conversations\n",
    "\n",
    "### ‚úÖ **Database Operations**\n",
    "- View all conversation threads\n",
    "- Retrieve conversation history\n",
    "- Monitor database statistics\n",
    "- Manage checkpoint data\n",
    "\n",
    "## Setup Requirements:\n",
    "\n",
    "### Required:\n",
    "- **langgraph-checkpoint**: `pip install langgraph-checkpoint`\n",
    "- **sqlite3**: Built into Python standard library\n",
    "\n",
    "### Optional:\n",
    "- **OpenAI API Key**: For real LLM responses (falls back to mock if not available)\n",
    "\n",
    "## Database Schema:\n",
    "\n",
    "The SQLite database automatically creates tables to store:\n",
    "- **checkpoints**: Main table storing conversation states\n",
    "- **thread_id**: Unique identifier for each conversation\n",
    "- **checkpoint_id**: Sequential ID for each state checkpoint\n",
    "- **metadata**: Additional information about each checkpoint\n",
    "\n",
    "## Use Cases:\n",
    "\n",
    "1. **Chat Applications**: Maintain conversation context across sessions\n",
    "2. **Multi-User Systems**: Separate conversations for different users\n",
    "3. **Complex Workflows**: Save intermediate states for long-running processes\n",
    "4. **Debugging**: Inspect conversation history and state transitions\n",
    "5. **Analytics**: Analyze conversation patterns and user interactions\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "1. Explore more complex state management patterns\n",
    "2. Implement user authentication with thread management\n",
    "3. Add conversation analytics and insights\n",
    "4. Build web interfaces with persistent memory\n",
    "5. Scale to production with proper database management\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a0f1593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Complete SQLite Memory Setup\n",
      "========================================\n",
      "‚úÖ SQLite checkpoint memory initialized successfully!\n",
      "Database path: d:\\Jeevan\\Agentic_AI\\LangGraph_Langchain\\LangGraph\\memory.db\n",
      "Connection status: Connected\n",
      "‚úÖ OpenAI LLM initialized\n",
      "‚úÖ LangGraph workflow with SQLite memory created!\n",
      "Features:\n",
      "  - Persistent conversation memory\n",
      "  - State checkpointing\n",
      "  - Thread-based conversations\n",
      "\n",
      "üéØ All variables are now available:\n",
      "  - sql_memory: SQLite checkpoint saver\n",
      "  - app: Compiled LangGraph workflow\n",
      "  - conn: Database connection\n",
      "  - llm: Language model\n",
      "\n",
      "‚úÖ Setup complete! You can now run the test cells.\n"
     ]
    }
   ],
   "source": [
    "# Complete Setup Cell - Run this if you get NameError\n",
    "print(\"üîß Complete SQLite Memory Setup\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Import all required modules\n",
    "import sqlite3\n",
    "import os\n",
    "from typing import Annotated, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Set up database path\n",
    "db_path = \"memory.db\"\n",
    "\n",
    "# Create database connection\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "\n",
    "# Create SQLite checkpoint saver\n",
    "sql_memory = SqliteSaver(conn)\n",
    "\n",
    "print(\"‚úÖ SQLite checkpoint memory initialized successfully!\")\n",
    "print(f\"Database path: {os.path.abspath(db_path)}\")\n",
    "print(f\"Connection status: {'Connected' if conn else 'Failed'}\")\n",
    "\n",
    "# Check for OpenAI API key and create LLM\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    print(\"‚ö†Ô∏è No OpenAI API key found. Using mock LLM for demonstration\")\n",
    "    \n",
    "    class MockLLM:\n",
    "        def invoke(self, messages):\n",
    "            return AIMessage(content=f\"Mock response to: {messages[-1].content}\")\n",
    "    \n",
    "    llm = MockLLM()\n",
    "else:\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "    print(\"‚úÖ OpenAI LLM initialized\")\n",
    "\n",
    "# Define the state for our graph\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def call_model(state: AgentState):\n",
    "    \"\"\"Call the LLM with the current messages.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Determine if we should continue the conversation.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Simple logic: continue if it's a human message\n",
    "    if isinstance(last_message, HumanMessage):\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"agent\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compile the graph with SQLite memory\n",
    "app = workflow.compile(checkpointer=sql_memory)\n",
    "\n",
    "print(\"‚úÖ LangGraph workflow with SQLite memory created!\")\n",
    "print(\"Features:\")\n",
    "print(\"  - Persistent conversation memory\")\n",
    "print(\"  - State checkpointing\")\n",
    "print(\"  - Thread-based conversations\")\n",
    "print(\"\\nüéØ All variables are now available:\")\n",
    "print(\"  - sql_memory: SQLite checkpoint saver\")\n",
    "print(\"  - app: Compiled LangGraph workflow\")\n",
    "print(\"  - conn: Database connection\")\n",
    "print(\"  - llm: Language model\")\n",
    "print(\"\\n‚úÖ Setup complete! You can now run the test cells.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d26d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
