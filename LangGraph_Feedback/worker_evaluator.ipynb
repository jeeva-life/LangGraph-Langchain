{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb218253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Jeevan\\Agentic_AI\\LangGraph_Langchain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, TypedDict, List, Dict, Any, Optional\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.agent_toolkits import PlayWrightBrowserToolkit\n",
    "from langchain_community.tools.playwright.utils import create_async_playwright_browser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd388a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluatorOutput(BaseModel):\n",
    "    feedback: str = Field(description=\"Feedback on the workers response\")\n",
    "    success_criteria_met: bool = Field(description= \"Whether the success criteria has benn met\")\n",
    "    user_input_needed: bool = Field(description=\"True if more input is needed from the user, or clarifications, or the assistant is stuck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2561a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The state\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    success_criteria: str\n",
    "    feedback_on_work: Optional[str]\n",
    "    success_criteria_met: bool\n",
    "    user_input_needed: bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963196ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize the LLM\u001b[39;00m\n\u001b[32m      3\u001b[39m worker_llm = ChatOpenAI(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, temperature=\u001b[32m0\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m worker_llm_with_tools = worker_llm.bind_tools(\u001b[43mtools\u001b[49m)\n\u001b[32m      7\u001b[39m evaluator_llm = ChatOpenAI(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, temperature=\u001b[32m0\u001b[39m)\n\u001b[32m      8\u001b[39m evaluator_llm_with_structured_output = evaluator_llm.with_structured_output(EvaluatorOutput)\n",
      "\u001b[31mNameError\u001b[39m: name 'tools' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "\n",
    "worker_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "worker_llm_with_tools = worker_llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "evaluator_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "evaluator_llm_with_structured_output = evaluator_llm.with_structured_output(EvaluatorOutput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e0cc7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32ccd608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The worker node\n",
    "\n",
    "def worker(state: State) -> Dict[str, Any]:\n",
    "    system_message= f\"\"\"you are a helpful assistant that can use tools to complete tasks\n",
    "    You keep working on a task until either you have a question or clarification for the user, or the success criteria is met\n",
    "    This is the success criteria: {state[\"success_criteria\"]}\n",
    "    you should reply either with a question for the user about this assignment, or with your final response.\n",
    "    If you have a question for the user, you need to reply by clearly stating that you are asking a question, and then ask the question.\n",
    "    \n",
    "    An example might be:\n",
    "\n",
    "    Question: Please clarify whether you want a summary or a detailed answer\n",
    "\n",
    "    If you have finished, reply with the final answer, and don't ask a question. simply reply with the answer.\n",
    "\"\"\"\n",
    "\n",
    "    if state.get(\"feedback_on_work\"):\n",
    "        system_message += f\"\"\"\n",
    "        Previously you thought you completed the assignment, but your reply was rejected because the success criteria was not met.\n",
    "        Here is the feedback of why this was rejected: {state[\"feedback_on_work\"]}\n",
    "        With this feedback in mind, please continue the assignment, ensuring that you meet the success criteria or ask for more information if needed.\n",
    "        \"\"\"\n",
    "\n",
    "        # Add in the system message to the messages\n",
    "\n",
    "        found_system_message = False\n",
    "        messages = state[\"messages\"]\n",
    "        for message in messages:\n",
    "            if isinstance(message, SystemMessage):\n",
    "                message.content = system_message\n",
    "                found_system_message = True\n",
    "        \n",
    "        if not found_system_message:\n",
    "            messages = [SystemMessage(content=system_message)] + messages\n",
    "\n",
    "        # Invoke the LLM with tools\n",
    "        response = [SystemMessage(content=system_message)] + messages\n",
    "\n",
    "        # return the updated state\n",
    "        return {\"messages\": [response],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac4a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_router(state: State) -> str:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"evaluator\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c95d13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_conversation(messages: List[Any]) -> str:\n",
    "    conversation = \"Conversation history:\\n\\n\"\n",
    "    for message in messages:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            conversation += f\"User: {message.content}\\n\"\n",
    "        elif isinstance(message, AIMessage):\n",
    "            text = message.content or \"[Tools use]\"\n",
    "            conversation += f\"Assistant: {text}\\n\"\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78dd8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(state: State) -> State:\n",
    "    last_response = state[\"messages\"][-1].content\n",
    "\n",
    "    system_message = f\"\"\"You are an evaluator that determines whether the assistant has met the success criteria.\n",
    "    Assess the Assistant's last response based on the given criteria. Respond with your feedback, and with your decision on whether the success criteria has been met,\n",
    "    and whether the user needs to provide more information.\"\"\"\n",
    "\n",
    "    user_message = f\"\"\"You are evaluating a conversation between the user and assistant. you decide what action to take based on the last response\n",
    "    The entire conversation with assistant, with the user's original request and all replies is:\n",
    "    {format_conversation(state['messages'])}\n",
    "\n",
    "    The success criteria for this assignment is:\n",
    "    {state['success_criteria']}\n",
    "\n",
    "    And the final response from the Assistant that you are evaluating is:\n",
    "    {last_response}\n",
    "\n",
    "    Respond with your feedback, and with your decision on whether the success criteria has been met,\n",
    "    Also decide if more user input is required, either because the assistant is stuck, or because the user needs to clarify their request.\"\"\"\n",
    "    \n",
    "    if state[\"feedback_on_work\"]:\n",
    "        user_message += f\"Also, note that in a prior atttempt from the assistant, you provided this feedback: {state['feedback_on_work']}\"\n",
    "        user_message += \"If you're seeing the Assistant repeating the same mistakes, then consider responding that user input is needed.\"\n",
    "\n",
    "    evaluator_messages = [SystemMessage(content=system_message), HumanMessage(content=user_message)]\n",
    "    \n",
    "    eval_result = evaluator_llm_with_output.invoke(evaluator_messages)\n",
    "    new_state = {\n",
    "        \"messages\": [{\"role\":\"assistant\", \"content\": f\"Evaluator Feedback on this answer: {eval_result.feedback}\"}],\n",
    "        \"feedback_on_work\": eval_result.feedback,\n",
    "        \"success_criteria_met\": eval_result.success_criteria_met,\n",
    "        \"user_input_needed\": eval_result.user_input_needed,\n",
    "    }\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5976ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_based_on_evaluator_result(state: State) -> str:\n",
    "    if state[\"success_criteria_met\"] or state[\"user_input_needed\"]:\n",
    "        return \"END\"\n",
    "    else:\n",
    "        return \"worker\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b58d07c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Add nodes\u001b[39;00m\n\u001b[32m      6\u001b[39m graph_builder.add_node(\u001b[33m\"\u001b[39m\u001b[33mworker\u001b[39m\u001b[33m\"\u001b[39m, worker)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m graph_builder.add_node(\u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m, ToolNode(tools=\u001b[43mtools\u001b[49m))\n\u001b[32m      8\u001b[39m graph_builder.add_node(\u001b[33m\"\u001b[39m\u001b[33mevaluator\u001b[39m\u001b[33m\"\u001b[39m, evaluator)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Add edges\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'tools' is not defined"
     ]
    }
   ],
   "source": [
    "# set up graph builder with state\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"worker\", worker)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "graph_builder.add_node(\"evaluator\", evaluator)\n",
    "\n",
    "# Add edges\n",
    "graph_builder.add_edge(START, \"worker\")\n",
    "graph_builder.add_conditional_edges(\"worker\", worker_router, {\"tools\": \"tools\", \"evaluator\": \"evaluator\"})\n",
    "graph_builder.add_edge(\"tools\", \"worker\")\n",
    "graph_builder.add_conditional_edges(\"evaluator\", route_based_on_evaluator_result, {\"END\": END, \"worker\": \"worker\"})\n",
    "\n",
    "# compile the Graph\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "009bbb76",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m display(Image(\u001b[43mgraph\u001b[49m.get_graph().draw_mermaid_png()))\n",
      "\u001b[31mNameError\u001b[39m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc3e8a",
   "metadata": {},
   "source": [
    "Next comes the gradio Callback to kick-off a super step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2dd604",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
