{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f932c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7421a095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284cde0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Set up OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    print(\"✓ OpenAI API key loaded successfully\")\n",
    "else:\n",
    "    print(\"⚠️ No OpenAI API key found - OpenAI features will not work\")\n",
    "    print(\"  Please add OPENAI_API_KEY to your .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af143f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LangChain API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Set up LangChain API key (optional for local usage)\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "if langchain_api_key:\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = langchain_api_key\n",
    "    print(\"✓ LangChain API key loaded successfully\")\n",
    "else:\n",
    "    print(\"ℹ No LangChain API key found - using local models only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf4aed6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mLANGCHAIN_TRACING_V2\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLANGCHAIN_PROJECT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mLANGCHAIN_PROJECT\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:690\u001b[39m, in \u001b[36m__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:750\u001b[39m, in \u001b[36mcheck_str\u001b[39m\u001b[34m(value)\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d972e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000002235F44A690> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002235F4F5CD0> root_client=<openai.OpenAI object at 0x000002235F4489B0> root_async_client=<openai.AsyncOpenAI object at 0x000002235F4F5B80> temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') max_tokens=1000\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=1000)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e7cd7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inout and get response from LLM\n",
    "response = llm.invoke(\"What is LangChain?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d42cc11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a decentralized language-learning platform that uses blockchain technology to connect language learners with native speakers for real-time language practice and conversation exchange. Users can earn tokens by helping others practice their language skills, which can then be used to pay for language lessons or other services on the platform. LangChain aims to make language learning more accessible, affordable, and interactive for people around the world.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69a71a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant that can answer questions.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that can answer questions.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fa5215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Quantum computing is a new paradigm of computing that utilizes the principles of quantum mechanics to perform operations on data. Unlike classical computers, which use bits to represent data as either 0s or 1s, quantum computers use quantum bits or qubits, which can represent both 0 and 1 simultaneously due to a property called superposition.\\n\\nThis allows quantum computers to perform certain types of calculations much faster than classical computers. Quantum computing has the potential to revolutionize fields such as cryptography, machine learning, optimization, and material science by solving complex problems that are currently intractable with classical computers.\\n\\nHowever, quantum computing is still in the early stages of development, and there are many technical challenges that need to be overcome before it can be widely adopted. Researchers and companies around the world are actively working on building more powerful and reliable quantum computers to unlock their full potential.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 174, 'prompt_tokens': 29, 'total_tokens': 203, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CDbq2iOY9IY4zq8TJTth3YaEhtDWD', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--58423d12-5033-4d12-8703-ab4ebadc4571-0' usage_metadata={'input_tokens': 29, 'output_tokens': 174, 'total_tokens': 203, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "response = chain.invoke({\"input\": \"can you tell me about quantum computing?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d22e6769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60ab61e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing is a rapidly advancing field of computing that utilizes principles of quantum mechanics to perform operations on data. Unlike classical computers that use bits as the basic unit of information, quantum computers use quantum bits or qubits. Qubits can exist in multiple states simultaneously, allowing quantum computers to perform complex calculations much faster than classical computers for certain types of problems.\n",
      "\n",
      "Quantum computing has the potential to revolutionize various fields such as cryptography, materials science, drug discovery, and optimization problems. Researchers and companies around the world are working on developing practical quantum computers that can outperform classical computers on specific tasks.\n",
      "\n",
      "However, quantum computing is still in its early stages, and there are many technical challenges that need to be overcome before quantum computers can be widely adopted. These challenges include improving qubit quality, error correction, and scalability of quantum systems. Nevertheless, quantum computing holds great promise for solving complex problems that are currently intractable for classical computers.\n"
     ]
    }
   ],
   "source": [
    "## string output parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"can you tell me about quantum computing?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe6c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858cb5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cbe350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39b334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d8703e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dbffaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f996ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97c651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e198dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LangChain components imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import LangChain components\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "print(\"✓ LangChain components imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bfafb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI Chat Model working!\n",
      "Response: LangChain is a decentralized platform that leverages blockchain technology to provide language learning services. The platform connects language learners with native speakers for language exchange, tutoring, and other language learning activities. Users can earn tokens by teaching their native language and use these tokens to pay for language lessons or other services on the platform. LangChain aims to create a global community of language learners and teachers, making language learning more accessible and affordable for everyone.\n"
     ]
    }
   ],
   "source": [
    "# Test OpenAI Chat Model (if API key is available)\n",
    "if openai_api_key:\n",
    "    try:\n",
    "        openai_llm = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=100\n",
    "        )\n",
    "        \n",
    "        # Test with a simple message\n",
    "        response = openai_llm.invoke(\"Hello! Can you tell me what LangChain is?\")\n",
    "        print(\"✓ OpenAI Chat Model working!\")\n",
    "        print(f\"Response: {response.content}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error with OpenAI Chat Model: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ Skipping OpenAI test - no API key available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23ed7e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ollama is running!\n",
      "Available models:\n"
     ]
    }
   ],
   "source": [
    "# Test Ollama LLM (if Ollama is running)\n",
    "import requests\n",
    "\n",
    "def check_ollama_status():\n",
    "    \"\"\"Check if Ollama is running.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            models = response.json()\n",
    "            print(\"✓ Ollama is running!\")\n",
    "            print(\"Available models:\")\n",
    "            for model in models.get('models', []):\n",
    "                print(f\"  - {model['name']}\")\n",
    "            return models.get('models', [])\n",
    "        else:\n",
    "            print(\"✗ Ollama is not responding properly\")\n",
    "            return []\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"✗ Ollama is not running. Please start Ollama first.\")\n",
    "        print(\"  You can start it by running: ollama serve\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error checking Ollama status: {e}\")\n",
    "        return []\n",
    "\n",
    "# Check Ollama status\n",
    "available_models = check_ollama_status()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4438f",
   "metadata": {},
   "source": [
    "# Getting Started with LangChain - OpenAI & Ollama\n",
    "\n",
    "This notebook demonstrates how to set up and use LangChain with both OpenAI and Ollama models.\n",
    "\n",
    "## Setup Requirements:\n",
    "\n",
    "### For OpenAI:\n",
    "1. Get an API key from [OpenAI](https://platform.openai.com/api-keys)\n",
    "2. Add it to your `.env` file: `OPENAI_API_KEY=your_key_here`\n",
    "\n",
    "### For Ollama:\n",
    "1. Install Ollama from [ollama.ai](https://ollama.ai)\n",
    "2. Start Ollama: `ollama serve`\n",
    "3. Pull a model: `ollama pull llama2` (or any other model)\n",
    "\n",
    "## Features Demonstrated:\n",
    "- ✅ Environment variable setup\n",
    "- ✅ OpenAI Chat Model integration\n",
    "- ✅ Ollama LLM integration\n",
    "- ✅ Error handling and status checking\n",
    "- ✅ Model availability detection\n",
    "\n",
    "## Next Steps:\n",
    "- Try different models and parameters\n",
    "- Explore LangChain's other components (embeddings, vector stores, etc.)\n",
    "- Build more complex applications with chains and agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca826b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
