{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19bbcae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì OpenAI API key loaded successfully\n",
      "‚úì LangSmith tracking configured\n",
      "‚úì User agent configured for web scraping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set up API keys\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    print(\"‚úì OpenAI API key loaded successfully\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No OpenAI API key found\")\n",
    "\n",
    "# Set up LangSmith tracking (optional)\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "if langchain_api_key:\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = langchain_api_key\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    langchain_project = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "    if langchain_project:\n",
    "        os.environ[\"LANGCHAIN_PROJECT\"] = langchain_project\n",
    "    print(\"‚úì LangSmith tracking configured\")\n",
    "else:\n",
    "    print(\"‚Ñπ No LangSmith tracking configured\")\n",
    "\n",
    "# Set USER_AGENT to avoid warnings when scraping websites\n",
    "os.environ[\"USER_AGENT\"] = \"LangChain-WebScraper/1.0 (Educational Purpose)\"\n",
    "print(\"‚úì User agent configured for web scraping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe3390cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Loading data from LangChain website...\n",
      "‚úì Successfully loaded 1 document(s)\n",
      "  Document length: 5402 characters\n",
      "  Source: https://langchain.com/\n"
     ]
    }
   ],
   "source": [
    "# DATA INGESTION -- Scrape data from the LangChain website\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "print(\"üåê Loading data from LangChain website...\")\n",
    "try:\n",
    "    loader = WebBaseLoader(\"https://langchain.com/\")\n",
    "    data = loader.load()\n",
    "    print(f\"‚úì Successfully loaded {len(data)} document(s)\")\n",
    "    print(f\"  Document length: {len(data[0].page_content)} characters\")\n",
    "    print(f\"  Source: {data[0].metadata.get('source', 'Unknown')}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error loading data: {e}\")\n",
    "    data = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f1d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Splitting document into chunks...\n",
      "‚úì Successfully split into 8 chunks\n",
      "  Average chunk size: 763 characters\n",
      "\n",
      "üìù First chunk preview:\n",
      "  Length: 750 characters\n",
      "  Content: LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Products\n",
      "\n",
      "FrameworksLangGraphLangChainPlatformsLangSmithLangGraph PlatformResources\n",
      "\n",
      "GuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogDocs\n",
      "\n",
      "PythonLangGr...\n"
     ]
    }
   ],
   "source": [
    "# TEXT SPLITTING -- Split the document into smaller chunks\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "if data:\n",
    "    print(\"üìÑ Splitting document into chunks...\")\n",
    "    try:\n",
    "        # Create text splitter\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,      # Size of each chunk\n",
    "            chunk_overlap=200,    # Overlap between chunks\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        )\n",
    "        \n",
    "        # Split the documents\n",
    "        chunks = text_splitter.split_documents(data)\n",
    "        print(f\"‚úì Successfully split into {len(chunks)} chunks\")\n",
    "        print(f\"  Average chunk size: {sum(len(chunk.page_content) for chunk in chunks) // len(chunks)} characters\")\n",
    "        \n",
    "        # Show first chunk as example\n",
    "        print(f\"\\n First chunk preview:\")\n",
    "        print(f\"  Length: {len(chunks[0].page_content)} characters\")\n",
    "        print(f\"  Content: {chunks[0].page_content[:200]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error splitting documents: {e}\")\n",
    "        chunks = None\n",
    "else:\n",
    "    print(\" No data available for splitting\")\n",
    "    chunks = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd78a8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://langchain.com/', 'title': 'LangChain', 'description': 'LangChain‚Äôs suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content='LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProducts\\n\\nFrameworksLangGraphLangChainPlatformsLangSmithLangGraph PlatformResources\\n\\nGuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogDocs\\n\\nPythonLangGraphLangSmithLangChainJavaScriptLangGraphLangSmithLangChainCompany\\n\\nAboutCareersPricingGet a demoSign up\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProducts\\n\\nFrameworksLangGraphLangChainPlatformsLangSmithLangGraph PlatformResources\\n\\nGuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogDocs\\n\\nPythonLangGraphLangSmithLangChainJavaScriptLangGraphLangSmithLangChainCompany\\n\\nAboutCareersPricingGet a demoSign upThe platform for reliable agents. Tools for every step of the agent development lifecycle -- built to unlock powerful AI\\xa0in production.Request a demoSee the docs'),\n",
       " Document(metadata={'source': 'https://langchain.com/', 'title': 'LangChain', 'description': 'LangChain‚Äôs suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content='LangChain products power top engineering teams, from startups to global enterprisesAccelerate agent development.Build faster with templates & a visual agent IDE. Reuse, configure, and combine agents to go further with less code.Ship reliable agents.Design agents that can handle sophisticated tasks with control. Add human-in-the-loop to steer and approve agent actions.Gain visibility & improve quality.See what‚Äôs happening - so you can quickly trace to root cause and debug issues. Evaluate your agent performance to improve over time.The Agent StackORCHESTRATION:Build agents with LangGraphControllable agent orchestration with built-in persistence to handle conversational history, memory, and agent-to-agent collaboration.INTEGRATIONS:Integrate components with LangChainIntegrate with the latest models, databases, and tools with no engineering overhead.EVALS\\xa0&\\xa0OBSERVABILITY:Gain visibility with LangSmithDebug poor-performing LLM app runs. Evaluate and observe agent performance at'),\n",
       " Document(metadata={'source': 'https://langchain.com/', 'title': 'LangChain', 'description': 'LangChain‚Äôs suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content='the latest models, databases, and tools with no engineering overhead.EVALS\\xa0&\\xa0OBSERVABILITY:Gain visibility with LangSmithDebug poor-performing LLM app runs. Evaluate and observe agent performance at scale.DEPLOYMENT:Deploy &\\xa0manage with LangGraph PlatformDeploy and scale enterprise-grade agents with long-running workflows. Discover, reuse, and share agents across teams ‚Äî and iterate faster with LangGraph Studio.CopilotsBuild native co-pilots into your application to unlock new end user experiences for domain-specific tasks.Enterprise GPTGive all employees access\\u2028to information and tools\\u2028in a compliant manner so they\\u2028can perform their best.Customer SupportImprove the speed & efficiency\\u2028of support teams that handle customer requests.ResearchSynthesize data, summarize sources & uncover insights faster than ever for knowledge work.Code generationAccelerate software development by automating code writing, refactoring, and documentation for your team.AI SearchOffer a concierge experience to'),\n",
       " Document(metadata={'source': 'https://langchain.com/', 'title': 'LangChain', 'description': 'LangChain‚Äôs suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content='faster than ever for knowledge work.Code generationAccelerate software development by automating code writing, refactoring, and documentation for your team.AI SearchOffer a concierge experience to guide users to products or information in a personalized way.'),\n",
       " Document(metadata={'source': 'https://langchain.com/', 'title': 'LangChain', 'description': 'LangChain‚Äôs suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content=\"LangChain products are designed to be used independently or stack for multiplicative benefit. LangChainLangGraphFrameworksLangSmithLangGraph PlatformPlatformsFrameworksLangChainLangGraphPlatformsLangSmithLangGraph \\u2028PlatformSTACK 1:\\xa0LangGraph +\\xa0LangChain +\\xa0LangSmith +\\xa0LangGraph\\xa0PlatformA full product suite for reliable agents and LLM appsLangChain's products work seamlessly together to provide an integrated solution for every step of the application development journey. When you use all LangChain products, you'll build better, get to production quicker, and grow visibility -- all with less set up and friction. LangChain provides the smoothest path to high quality agents.Orchestration:Integrations:Evals + Observability:Deployment:STACK 2: No framework +\\xa0LangSmithTrace\\xa0and evaluate any LLM appLangSmith is framework-agnostic. Trace using the TypeScript or Python SDK\\xa0to gain visibility into your agent interactions -- whether you use LangChain's frameworks or not.Orchestration:Your\"),\n",
       " Document(metadata={'source': 'https://langchain.com/', 'title': 'LangChain', 'description': 'LangChain‚Äôs suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content=\"LLM appLangSmith is framework-agnostic. Trace using the TypeScript or Python SDK\\xa0to gain visibility into your agent interactions -- whether you use LangChain's frameworks or not.Orchestration:Your choiceEvals + Observability:STACK 3:\\xa0Any agent framework +\\xa0LangGraph PlatformBuild agents any way you want, then deploy and scale with easeLangGraph Platform works with any agent framework, enabling stateful UXs like human-in-the-loop and streaming-native deployments.Orchestration:Your choiceDeployment:Get inspired by companies who have done it.Teams building with LangChain products are driving operational efficiency, increasing discovery & personalization, and delivering premium products that generate revenue.Discover Use Cases\"),\n",
       " Document(metadata={'source': 'https://langchain.com/', 'title': 'LangChain', 'description': 'LangChain‚Äôs suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content=\"Financial ServicesKlarna's AI assistant has reduced average customer query resolution time by 80%, powered by LangSmith and LangGraph\\n\\n\\nTransportationThis global logistics provider is saving 600 hours a day using an automated order system built on LangGraph and LangSmith\\n\\n\\nSecurityAs a leading cybersecurity firm with 40k+ customers, Trellix cut log parsing from days to minutes using LangGraph and LangSmith.\"),\n",
       " Document(metadata={'source': 'https://langchain.com/', 'title': 'LangChain', 'description': 'LangChain‚Äôs suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content='SecurityAs a leading cybersecurity firm with 40k+ customers, Trellix cut log parsing from days to minutes using LangGraph and LangSmith.\\n\\n\\nThe biggest developer community in GenAILearn alongside the 1M+ practitioners using our frameworks to push the industry forward.#1Downloaded agent framework100k+GitHub stars#1Downloaded agent framework600+IntegrationsReady to start shipping \\u2028reliable agents faster?Get started with tools from the LangChain product suite for every step of the agent development lifecycle.Get a demoSign up for freeProductsLangChainLangSmithLangGraphResourcesGuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogExpertsPython DocsLangGraph LangSmithLangChainJS DocsLangGraphLangSmithLangChainCompanyAboutCareersXLinkedInYouTubeMarketing AssetsSecuritySign up for our newsletter to stay up to dateThank you! Your submission has been received!Oops! Something went wrong while submitting the form.All systems operationalPrivacy PolicyTerms of Service')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c3a0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "519aaa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  langchain_community.vectorstores import FAISS\n",
    "vector_store_db = FAISS.from_documents(chunks, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2717ce62630>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50bd9e2",
   "metadata": {},
   "source": [
    "RETRIEVERS & CHAINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5af6e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Langsmith has 2 usage limits: total traces and extended\"\n",
    "result = vector_store_db.similarity_search(query, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "affa7478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangChain products are designed to be used independently or stack for multiplicative benefit. LangChainLangGraphFrameworksLangSmithLangGraph PlatformPlatformsFrameworksLangChainLangGraphPlatformsLangSmithLangGraph \\u2028PlatformSTACK 1:\\xa0LangGraph +\\xa0LangChain +\\xa0LangSmith +\\xa0LangGraph\\xa0PlatformA full product suite for reliable agents and LLM appsLangChain's products work seamlessly together to provide an integrated solution for every step of the application development journey. When you use all LangChain products, you'll build better, get to production quicker, and grow visibility -- all with less set up and friction. LangChain provides the smoothest path to high quality agents.Orchestration:Integrations:Evals + Observability:Deployment:STACK 2: No framework +\\xa0LangSmithTrace\\xa0and evaluate any LLM appLangSmith is framework-agnostic. Trace using the TypeScript or Python SDK\\xa0to gain visibility into your agent interactions -- whether you use LangChain's frameworks or not.Orchestration:Your\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5d60395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a699fd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n Answer the question based on the context provided.\\n <context>\\n {context}\\n </context>\\n '), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002717FEB19D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002717D024350>, root_client=<openai.OpenAI object at 0x0000027169A4D7F0>, root_async_client=<openai.AsyncOpenAI object at 0x000002717FEB0320>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### retrieval chain, Documents chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    " \"\"\"\n",
    " Answer the question based on the context provided.\n",
    " <context>\n",
    " {context}\n",
    " </context>\n",
    " \"\"\"\n",
    ")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51e8521d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The question is not provided.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document_chain.invoke({\n",
    "    \"input\": \"langcmith has 2 usage limits: total traces and extended\",\n",
    "    \"context\": [Document(page_content=\"Langsmith has 2 usage limits: total traces and extended\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2717ce62630>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Input --> Retriever --> vectorstoredb\n",
    "vector_store_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c42c2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002717CE62630>, search_kwargs={})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0faffd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002717CE62630>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n Answer the question based on the context provided.\\n <context>\\n {context}\\n </context>\\n '), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002717FEB19D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002717D024350>, root_client=<openai.OpenAI object at 0x0000027169A4D7F0>, root_async_client=<openai.AsyncOpenAI object at 0x000002717FEB0320>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(\n",
    "    retriever=vector_store_db.as_retriever(),\n",
    "    combine_docs_chain=document_chain\n",
    ")\n",
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64b2a010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'langcmith has 2 usage limits: total traces and extended',\n",
       " 'context': [Document(id='ba6df6ac-61a5-41f8-8a9a-55eb532382a0', metadata={'source': 'https://langchain.com/', 'title': 'LangChain', 'description': 'LangChain‚Äôs suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content=\"LangChain products are designed to be used independently or stack for multiplicative benefit. LangChainLangGraphFrameworksLangSmithLangGraph PlatformPlatformsFrameworksLangChainLangGraphPlatformsLangSmithLangGraph \\u2028PlatformSTACK 1:\\xa0LangGraph +\\xa0LangChain +\\xa0LangSmith +\\xa0LangGraph\\xa0PlatformA full product suite for reliable agents and LLM appsLangChain's products work seamlessly together to provide an integrated solution for every step of the application development journey. When you use all LangChain products, you'll build better, get to production quicker, and grow visibility -- all with less set up and friction. LangChain provides the smoothest path to high quality agents.Orchestration:Integrations:Evals + Observability:Deployment:STACK 2: No framework +\\xa0LangSmithTrace\\xa0and evaluate any LLM appLangSmith is framework-agnostic. Trace using the TypeScript or Python SDK\\xa0to gain visibility into your agent interactions -- whether you use LangChain's frameworks or not.Orchestration:Your\"),\n",
       "  Document(id='073e5ef7-2e68-4fdb-9385-834d14f1120a', metadata={'source': 'https://langchain.com/', 'title': 'LangChain', 'description': 'LangChain‚Äôs suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content=\"LLM appLangSmith is framework-agnostic. Trace using the TypeScript or Python SDK\\xa0to gain visibility into your agent interactions -- whether you use LangChain's frameworks or not.Orchestration:Your choiceEvals + Observability:STACK 3:\\xa0Any agent framework +\\xa0LangGraph PlatformBuild agents any way you want, then deploy and scale with easeLangGraph Platform works with any agent framework, enabling stateful UXs like human-in-the-loop and streaming-native deployments.Orchestration:Your choiceDeployment:Get inspired by companies who have done it.Teams building with LangChain products are driving operational efficiency, increasing discovery & personalization, and delivering premium products that generate revenue.Discover Use Cases\"),\n",
       "  Document(id='6c410b54-30d3-4a72-926e-f55677624972', metadata={'source': 'https://langchain.com/', 'title': 'LangChain', 'description': 'LangChain‚Äôs suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content='LangChain products power top engineering teams, from startups to global enterprisesAccelerate agent development.Build faster with templates & a visual agent IDE. Reuse, configure, and combine agents to go further with less code.Ship reliable agents.Design agents that can handle sophisticated tasks with control. Add human-in-the-loop to steer and approve agent actions.Gain visibility & improve quality.See what‚Äôs happening - so you can quickly trace to root cause and debug issues. Evaluate your agent performance to improve over time.The Agent StackORCHESTRATION:Build agents with LangGraphControllable agent orchestration with built-in persistence to handle conversational history, memory, and agent-to-agent collaboration.INTEGRATIONS:Integrate components with LangChainIntegrate with the latest models, databases, and tools with no engineering overhead.EVALS\\xa0&\\xa0OBSERVABILITY:Gain visibility with LangSmithDebug poor-performing LLM app runs. Evaluate and observe agent performance at'),\n",
       "  Document(id='8c2dd0d7-ad57-4930-8a17-6ae33e61c092', metadata={'source': 'https://langchain.com/', 'title': 'LangChain', 'description': 'LangChain‚Äôs suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content='SecurityAs a leading cybersecurity firm with 40k+ customers, Trellix cut log parsing from days to minutes using LangGraph and LangSmith.\\n\\n\\nThe biggest developer community in GenAILearn alongside the 1M+ practitioners using our frameworks to push the industry forward.#1Downloaded agent framework100k+GitHub stars#1Downloaded agent framework600+IntegrationsReady to start shipping \\u2028reliable agents faster?Get started with tools from the LangChain product suite for every step of the agent development lifecycle.Get a demoSign up for freeProductsLangChainLangSmithLangGraphResourcesGuidesBlogCustomer StoriesLangChain AcademyCommunityEventsChangelogExpertsPython DocsLangGraph LangSmithLangChainJS DocsLangGraphLangSmithLangChainCompanyAboutCareersXLinkedInYouTubeMarketing AssetsSecuritySign up for our newsletter to stay up to dateThank you! Your submission has been received!Oops! Something went wrong while submitting the form.All systems operationalPrivacy PolicyTerms of Service')],\n",
       " 'answer': 'LangChain products are designed to be used independently or stacked for multiplicative benefit.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the response from the LLM\n",
    "response = retrieval_chain.invoke({\"input\": \"langcmith has 2 usage limits: total traces and extended\"})\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d96e3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain products are designed to be used independently or stacked for multiplicative benefit.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c455127b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405cdcf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71593a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a608f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDINGS -- Create embeddings for the document chunks\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "if chunks and openai_api_key:\n",
    "    print(\"üîÆ Creating embeddings for document chunks...\")\n",
    "    try:\n",
    "        # Create embeddings\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        \n",
    "        # Generate embeddings for all chunks\n",
    "        print(\"  Generating embeddings (this may take a moment)...\")\n",
    "        chunk_embeddings = embeddings.embed_documents([chunk.page_content for chunk in chunks])\n",
    "        \n",
    "        print(f\"‚úì Successfully created {len(chunk_embeddings)} embeddings\")\n",
    "        print(f\"  Embedding dimensions: {len(chunk_embeddings[0])}\")\n",
    "        print(f\"  First embedding (first 5 values): {chunk_embeddings[0][:5]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error creating embeddings: {e}\")\n",
    "        chunk_embeddings = None\n",
    "        embeddings = None\n",
    "else:\n",
    "    if not chunks:\n",
    "        print(\"‚ö†Ô∏è No chunks available for embedding\")\n",
    "    if not openai_api_key:\n",
    "        print(\"‚ö†Ô∏è No OpenAI API key available for embeddings\")\n",
    "    chunk_embeddings = None\n",
    "    embeddings = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba30ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VECTOR STORE -- Store embeddings in a vector database\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "if chunks and embeddings:\n",
    "    print(\"üóÑÔ∏è Creating vector store...\")\n",
    "    try:\n",
    "        # Create Chroma vector store\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=\"./chroma_db\"  # Local storage\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Successfully created vector store with {len(chunks)} documents\")\n",
    "        print(\"  Vector store saved to: ./chroma_db\")\n",
    "        \n",
    "        # Test similarity search\n",
    "        print(\"\\nüîç Testing similarity search...\")\n",
    "        test_query = \"What is LangChain?\"\n",
    "        similar_docs = vectorstore.similarity_search(test_query, k=2)\n",
    "        \n",
    "        print(f\"Query: '{test_query}'\")\n",
    "        print(f\"Found {len(similar_docs)} similar documents:\")\n",
    "        for i, doc in enumerate(similar_docs):\n",
    "            print(f\"  {i+1}. Length: {len(doc.page_content)} chars\")\n",
    "            print(f\"     Preview: {doc.page_content[:100]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error creating vector store: {e}\")\n",
    "        vectorstore = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cannot create vector store - missing chunks or embeddings\")\n",
    "    vectorstore = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfe3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETRIEVAL QA CHAIN -- Create a question-answering system\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "if vectorstore and openai_api_key:\n",
    "    print(\"ü§ñ Creating Retrieval QA Chain...\")\n",
    "    try:\n",
    "        # Create the LLM\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        # Create the retrieval QA chain\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "            return_source_documents=True\n",
    "        )\n",
    "        \n",
    "        print(\"‚úì Retrieval QA Chain created successfully!\")\n",
    "        \n",
    "        # Test the QA system\n",
    "        print(\"\\n‚ùì Testing Question Answering...\")\n",
    "        test_questions = [\n",
    "            \"What is LangChain?\",\n",
    "            \"What are the main features of LangChain?\",\n",
    "            \"How can I get started with LangChain?\"\n",
    "        ]\n",
    "        \n",
    "        for question in test_questions:\n",
    "            print(f\"\\nQ: {question}\")\n",
    "            try:\n",
    "                result = qa_chain.invoke({\"query\": question})\n",
    "                print(f\"A: {result['result']}\")\n",
    "                print(f\"   Sources: {len(result['source_documents'])} documents used\")\n",
    "            except Exception as e:\n",
    "                print(f\"   Error: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error creating QA chain: {e}\")\n",
    "        qa_chain = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cannot create QA chain - missing vector store or API key\")\n",
    "    qa_chain = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521836fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERACTIVE QA -- Create an interactive question-answering function\n",
    "def ask_question(question):\n",
    "    \"\"\"Ask a question to the QA system.\"\"\"\n",
    "    if qa_chain:\n",
    "        try:\n",
    "            result = qa_chain.invoke({\"query\": question})\n",
    "            return {\n",
    "                \"answer\": result['result'],\n",
    "                \"sources\": len(result['source_documents']),\n",
    "                \"source_docs\": result['source_documents']\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    else:\n",
    "        return {\"error\": \"QA chain not available\"}\n",
    "\n",
    "# Example usage\n",
    "if qa_chain:\n",
    "    print(\"üéØ Interactive Question Answering System Ready!\")\n",
    "    print(\"You can now ask questions about LangChain using the ask_question() function.\")\n",
    "    print(\"\\nExample:\")\n",
    "    \n",
    "    # Test with a sample question\n",
    "    sample_result = ask_question(\"What is LangChain used for?\")\n",
    "    if \"error\" not in sample_result:\n",
    "        print(f\"Q: What is LangChain used for?\")\n",
    "        print(f\"A: {sample_result['answer']}\")\n",
    "        print(f\"   Sources: {sample_result['sources']} documents\")\n",
    "    else:\n",
    "        print(f\"Error: {sample_result['error']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Interactive QA system not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc863bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5071f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a163911c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1a91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
