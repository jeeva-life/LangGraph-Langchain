{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa5a6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ollama is running!\n",
      "Available models:\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Check if Ollama is running and what models are available\n",
    "def check_ollama_status():\n",
    "    \"\"\"Check if Ollama is running and list available models.\"\"\"\n",
    "    try:\n",
    "        # Check if Ollama is running\n",
    "        response = requests.get(\"http://localhost:11434/api/tags\")\n",
    "        if response.status_code == 200:\n",
    "            models = response.json()\n",
    "            print(\"✓ Ollama is running!\")\n",
    "            print(\"Available models:\")\n",
    "            for model in models.get('models', []):\n",
    "                print(f\"  - {model['name']}\")\n",
    "            return models.get('models', [])\n",
    "        else:\n",
    "            print(\"✗ Ollama is not responding properly\")\n",
    "            return []\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"✗ Ollama is not running. Please start Ollama first.\")\n",
    "        print(\"  You can start it by running: ollama serve\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error checking Ollama status: {e}\")\n",
    "        return []\n",
    "\n",
    "# Check Ollama status\n",
    "available_models = check_ollama_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b14bf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No models available. Please install a model first.\n"
     ]
    }
   ],
   "source": [
    "# Function to create embeddings with available models\n",
    "def create_ollama_embeddings(model_name=None):\n",
    "    \"\"\"Create Ollama embeddings with the specified model or find a suitable one.\"\"\"\n",
    "    if not available_models:\n",
    "        print(\"No models available. Please install a model first.\")\n",
    "        return None\n",
    "    \n",
    "    # If no model specified, try to find a suitable embedding model\n",
    "    if not model_name:\n",
    "        # Look for common embedding models\n",
    "        embedding_models = ['nomic-embed-text', 'all-minilm', 'mxbai-embed-large']\n",
    "        for model in available_models:\n",
    "            model_name = model['name']\n",
    "            if any(embed_model in model_name.lower() for embed_model in embedding_models):\n",
    "                print(f\"Using available embedding model: {model_name}\")\n",
    "                break\n",
    "        else:\n",
    "            # If no embedding model found, use the first available model\n",
    "            model_name = available_models[0]['name']\n",
    "            print(f\"No specific embedding model found. Using: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        embeddings = OllamaEmbeddings(model=model_name)\n",
    "        print(f\"✓ Successfully created embeddings with model: {model_name}\")\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error creating embeddings with {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = create_ollama_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06776ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No embeddings object created. Please check Ollama setup.\n"
     ]
    }
   ],
   "source": [
    "# Display embeddings configuration\n",
    "if embeddings:\n",
    "    print(\"Embeddings Configuration:\")\n",
    "    print(f\"  Model: {embeddings.model}\")\n",
    "    print(f\"  Base URL: {embeddings.base_url}\")\n",
    "    print(f\"  Embed Instruction: {embeddings.embed_instruction}\")\n",
    "    print(f\"  Query Instruction: {embeddings.query_instruction}\")\n",
    "else:\n",
    "    print(\"No embeddings object created. Please check Ollama setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d69c6cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot test embeddings - no embeddings object available\n"
     ]
    }
   ],
   "source": [
    "# Test embeddings with sample documents\n",
    "if embeddings:\n",
    "    print(\"Testing document embeddings...\")\n",
    "    try:\n",
    "        sample_texts = [\"this is a test\", \"this is a test 2\", \"machine learning is fascinating\"]\n",
    "        r1 = embeddings.embed_documents(sample_texts)\n",
    "        print(f\"✓ Successfully created {len(r1)} embeddings\")\n",
    "        print(f\"  Each embedding has {len(r1[0])} dimensions\")\n",
    "        print(f\"  First embedding (first 5 values): {r1[0][:5]}\")\n",
    "        \n",
    "        # Test query embedding\n",
    "        print(\"\\nTesting query embedding...\")\n",
    "        query_embedding = embeddings.embed_query(\"this is a query\")\n",
    "        print(f\"✓ Query embedding created successfully\")\n",
    "        print(f\"  Query embedding dimensions: {len(query_embedding)}\")\n",
    "        print(f\"  Query embedding (first 5 values): {query_embedding[:5]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error creating embeddings: {e}\")\n",
    "        print(\"This might be because:\")\n",
    "        print(\"  1. The model doesn't support embeddings\")\n",
    "        print(\"  2. Ollama is not running\")\n",
    "        print(\"  3. The model needs to be pulled first\")\n",
    "        print(\"\\nTo fix this, try:\")\n",
    "        print(\"  1. Start Ollama: ollama serve\")\n",
    "        print(\"  2. Pull an embedding model: ollama pull nomic-embed-text\")\n",
    "else:\n",
    "    print(\"Cannot test embeddings - no embeddings object available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77cc7f",
   "metadata": {},
   "source": [
    "# Ollama Embeddings with LangChain\n",
    "\n",
    "This notebook demonstrates how to use Ollama embeddings with LangChain.\n",
    "\n",
    "## Prerequisites:\n",
    "1. **Install Ollama**: Download from [ollama.ai](https://ollama.ai)\n",
    "2. **Start Ollama**: Run `ollama serve` in terminal\n",
    "3. **Pull an embedding model**: Run `ollama pull nomic-embed-text`\n",
    "\n",
    "## Recommended Embedding Models:\n",
    "- `nomic-embed-text` - Good general purpose embeddings\n",
    "- `all-minilm` - Lightweight and fast\n",
    "- `mxbai-embed-large` - High quality embeddings\n",
    "\n",
    "## Common Issues:\n",
    "- **Model not found**: Pull the model first with `ollama pull <model-name>`\n",
    "- **Connection error**: Make sure Ollama is running with `ollama serve`\n",
    "- **404 error**: The model might not support embeddings (use embedding-specific models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76678923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
